# [OLIVAW: Mastering Othello with neither Humans nor a Penny](https://arxiv.org/abs/2103.17228) の日本語訳

Antonio Norelli 氏に許可をいただいて公開しています。  
脚注については原文を参照して下さい。  

【目次】
<!--ts-->
<!--te-->

以下翻訳。

---
## 概要
あの有名な AlphaGo シリーズの設計原理を採用した AI オセロプレイヤーである、OLIVAW を紹介します。  
OLIVAW の主に目指すことは、これまでのいくつもの偉大なアプローチと比べて低コストで、非自明なボードゲームにおける卓越した棋力を得ることです。  
本論文では、AlphaGo Zero のパラダイムが、コモディティハードウェアと無料のクラウドサービスだけを使って、人気のあるゲームであるオセロにうまく適用できることを示します。  
オセロは、チェスや囲碁に比べてシンプルなゲームですが、巨大な探索空間を持ち、盤面を評価するのが難しいゲームです。  
OLIVAW では、AlphaGo Zero の標準的な学習プロセスを高速化するために、最近の研究にヒントを得ていくつかの改良を行っています。  
主な改良点は、学習段階でゲームごとに収集される盤面情報を2倍にすることです。これは、エージェントがプレイしていないものの、深く探索した盤面も含めることによって実現しています。  
我々は、OLIVAW の強さを3つの異なる方法でテストしました。  
* 最強のオープンソースオセロエンジンである Edax との対戦
* ウェブプラットフォーム OthelloQuest での匿名対局
* 人間の一流プレイヤーとの対戦
  * vs 全米チャンピオン
  * vs 元世界チャンピオン

## 索引用語

Deep Learning, Computational Efficiency, Neural Networks, Monte Carlo methods, Board Games, Othello

## I. 導入
AlphaGo が囲碁界の巨匠 Lee Sedol に勝利してからわずか1年後、またしても扇情的な出来事が起こりました。  
AlphaGo Zero と呼ばれる AlphaGo の改良版が史上最強の囲碁プレイヤーであることを主張したのです。[1]  
AlphaGo Zero の注目すべき点は、これまでのソフトウェアとは異なり、人間の知識を一切必要とせず、独学でゲームを極めたことである。  
その後の研究ですぐに明らかになりましたが、AlphaGo のパラダイムは、深層学習と強化学習の興味深い融合でした。  
そして、それは一般的でありつつ柔軟性を持っていたため、さまざまなゲームに適用可能らしいことも分かりました。[2], [3]

しかし、この驚異的な成功には、文字通りの代償がありました。本当に文字通りの意味です。  
その代償とは、膨大な計算機と資金を必要とすることであり、ほとんどの学術機関や非学術機関では手の届かない手法でした。  
偶然ではありませんが、これらの恵まれたプロジェクトは、IT分野の巨大な多国籍企業で行われたのです。[4], [5]
それらの企業は、数千の GPU と数百の TPU を導入しました。  
最近の研究に、AlphaGo Zero やその他の有名な AI を訓練するために、どのくらいの PFLOPS が必要とされるかを調べた論文があります。[6]  
その論文では、3,4ヶ月で2倍になるという、指数関数的な成長が示されています。  
これは、ほとんどの大学の研究室や学科、さらには大多数の企業にとって、明らかに持続不可能です。  
別の側面として、必要なトレーニングの量の問題があります。
AlphaGo Zero では、自己対戦で 490 万回の対局を行われました。一方、「Starcraft II」や「Dota 2」のようなゲームでグランドマスターレベルに到達するには、それぞれ 200年、1万年以上のゲームプレイを必要としました。[7], [8]
